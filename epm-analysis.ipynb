{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elevated-plus maze analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T20:57:49.661245Z",
     "start_time": "2018-02-13T20:57:48.745976Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "import os\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdf(array, ax=None, ignore_nan=True, **kwargs):\n",
    "    '''Creates cumulative distribution function from array of data points\n",
    "    Parameters\n",
    "    ----------\n",
    "    array : array_like\n",
    "        Array to plot CDF. If more than one dimension, array will be flattened.\n",
    "    ax : Axes object, optional\n",
    "        Axes on which to plot CDF.\n",
    "    ignore_nan : boolean\n",
    "        Whether to ignore nan values in `array`.\n",
    "    **kwargs: keyword arguments\n",
    "        Keyword arguments for matplotlib.pyplot.plot.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    ax: axes object containing CDF\n",
    "\n",
    "    '''\n",
    "    array = np.array(array).flatten()\n",
    "    if ignore_nan:\n",
    "        array = array[~ np.isnan(array)]\n",
    "\n",
    "    X = np.sort(array)\n",
    "    Y = (np.arange(len(array), dtype=float) + 1) / len(array)\n",
    "    if ax:\n",
    "        ax.plot(X, Y, **kwargs)\n",
    "    else:\n",
    "        plt.plot(X, Y, **kwargs)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T20:57:49.954461Z",
     "start_time": "2018-02-13T20:57:49.663027Z"
    }
   },
   "outputs": [],
   "source": [
    "neural_file = 'epm-neural.csv'\n",
    "behav_file = 'epm-behav.csv'\n",
    "\n",
    "save_plot = False\n",
    "output_dir = './results'\n",
    "if output_dir and not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural = pd.read_csv(neural_file, header=[0, 1], index_col=0)\n",
    "behav = pd.read_csv(behav_file, header=[0, 1], index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bin neural activity\n",
    "Calculate mean neural activity in discrete bins along arms of EPM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T20:59:04.822651Z",
     "start_time": "2018-02-13T20:59:04.740693Z"
    }
   },
   "outputs": [],
   "source": [
    "n_bins = 10\n",
    "max_d = 35\n",
    "bins = np.arange(n_bins + 1, dtype=float) / n_bins * max_d\n",
    "bins = np.insert(bins, 0, -1)\n",
    "bin_labels = np.arange(0, n_bins+1) / 10.\n",
    "binned_loc = pd.cut(behav.xs('distance_from_center', axis=1, level='feature').stack('subject'), bins, labels=bin_labels).unstack('subject')\n",
    "binned_loc.columns = pd.MultiIndex.from_product([binned_loc.columns, ['distance_from_center']], names=['subject', 'feature'])\n",
    "\n",
    "df_zone = behav.loc[:, (slice(None), ['in_center', 'in_closed', 'in_open'])].astype(bool).sort_index(axis=1)\n",
    "for subj, df in df_zone.groupby(axis=1, level='subject'):\n",
    "    df_zone[(subj, 'zone')] = pd.Series(['center' if x else 'closed' if y else 'open' if z else 'na' for (x, y, z), in zip(df.values)], index=df.index)\n",
    "\n",
    "df_loc = pd.concat([binned_loc, df_zone], axis=1).sort_index(axis=1)\n",
    "\n",
    "loc = df_loc.loc[:, (slice(None), ['zone', 'distance_from_center'])]\n",
    "dfs = {}\n",
    "for subj, df in df_loc.groupby(axis=1, level='subject'):\n",
    "    dfs[subj] = pd.concat([loc[subj], neural[subj]], axis=1).groupby(['distance_from_center', 'zone']).mean()\n",
    "\n",
    "neural_zone = pd.concat(dfs, axis=1, names=['subject', 'neuron'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group neurons\n",
    "Determine response of neurons based on difference in activity between open and closed arm using Mann Whitney U test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T20:59:09.821382Z",
     "start_time": "2018-02-13T20:59:08.760450Z"
    }
   },
   "outputs": [],
   "source": [
    "# Average activity by location\n",
    "\n",
    "n_cells = neural.shape[1]\n",
    "p_thresh = 0.05 / n_cells #neural_arm.shape[0]\n",
    "center_col = 'in_center'\n",
    "closed_col = 'in_closed'\n",
    "open_col = 'in_open'\n",
    "\n",
    "# Average activity for each neuron in each zone\n",
    "neural_arm = pd.DataFrame(\n",
    "    index=neural.columns,\n",
    "    columns=['center', 'open', 'closed'],\n",
    "    dtype=float\n",
    ")\n",
    "neural_arm.columns.name = 'arm'\n",
    "neural_response = pd.DataFrame(index=['group', 'difference', 'p'], columns=neural.columns, dtype=float)\n",
    "\n",
    "for subj, df in neural.groupby(axis=1, level='subject'):\n",
    "    center_ix = behav[(subj, center_col)] == 1\n",
    "    closed_ix = behav[(subj, closed_col)] == 1\n",
    "    open_ix = behav[(subj, open_col)] == 1\n",
    "    \n",
    "    neural_arm.loc[subj, 'center'] = df.loc[center_ix, :].mean(axis=0)\n",
    "    neural_arm.loc[subj, 'closed'] = df.loc[closed_ix, :].mean(axis=0)\n",
    "    neural_arm.loc[subj, 'open'] = df.loc[open_ix, :].mean(axis=0)\n",
    "    \n",
    "    for cell in df.loc[:, subj]:\n",
    "        X1 = df.loc[closed_ix, (slice(None), cell)]\n",
    "        X2 = df.loc[open_ix, (slice(None), cell)]\n",
    "        _, neural_response.loc['p', (subj, cell)] = scipy.stats.mannwhitneyu(X1, X2)\n",
    "\n",
    "# Calculate difference between arms\n",
    "neural_response.loc['difference'] = (neural_arm['open'] - neural_arm['closed'])\n",
    "significant_ix = neural_response.loc['p'] < p_thresh\n",
    "\n",
    "# Define groups\n",
    "neural_response.loc['group'] = 0\n",
    "exc_ix = neural_response.loc['difference'] > 0\n",
    "inh_ix = neural_response.loc['difference'] < 0\n",
    "neural_response.loc['group', neural_response.columns[significant_ix & exc_ix]] = 1\n",
    "neural_response.loc['group', neural_response.columns[significant_ix & inh_ix]] = -1\n",
    "\n",
    "# Add groups to `neural_arm`\n",
    "neural_arm.index = pd.MultiIndex.from_tuples(\n",
    "    [x + (neural_response.loc['group', x], ) for x in neural_arm.index],\n",
    "    names = ['subject', 'neuron', 'response']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = neural_response.loc['group', :].astype(int).to_dict()\n",
    "neural_grp = neural.copy()\n",
    "neural_grp.columns = pd.MultiIndex.from_tuples([x + (groups[x], ) for x in neural], names=neural.columns.names + ['group'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural-behavior Correlations\n",
    "Calculate Spearman correlation coefficient between behavioral features and neural activity within the open arm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distance-activity correlations\n",
    "\n",
    "features = ['distance_from_center', 'velocity']\n",
    "neural_corr = pd.DataFrame(\n",
    "    index=neural_grp.columns,\n",
    "    columns=pd.MultiIndex.from_product(\n",
    "        [['open', 'closed'], features, ['r', 'p']],\n",
    "        names=['arm', 'feature', 'stat']\n",
    "    ),\n",
    "    dtype=float\n",
    ")\n",
    "neural_corr_stats = pd.DataFrame(\n",
    "    index=[-1, 0, 1],\n",
    "    columns=pd.MultiIndex.from_product(\n",
    "        [['open', 'closed'], features, ['t', 'p']],\n",
    "        names=['arm', 'feature', 'stat']\n",
    "    )\n",
    ")\n",
    "\n",
    "for feature in features:\n",
    "    for subj, df_subj in neural_grp.groupby(axis=1, level='subject'):\n",
    "        closed_ts = behav.index[behav[subj, 'in_closed'] == 1]\n",
    "        open_ts = behav.index[behav[subj, 'in_open'] == 1]\n",
    "        for cell in df_subj:\n",
    "            for arm, arm_ix in zip(['open', 'closed'], [open_ts, closed_ts]):\n",
    "                X = df_subj.loc[arm_ix, cell]\n",
    "                Y = behav[subj, feature][arm_ix]\n",
    "                ix = ~(X.isna() | Y.isna())\n",
    "\n",
    "                (\n",
    "                    neural_corr.loc[cell, (arm, feature, 'r')],\n",
    "                    neural_corr.loc[cell, (arm, feature, 'p')]\n",
    "                ) = scipy.stats.spearmanr(X[ix], Y[ix])\n",
    "\n",
    "# Stats on correlation distributions\n",
    "for arm in ['closed', 'open']:\n",
    "    for feature in features:\n",
    "        for grp in [-1, 0, 1]:\n",
    "            neural_corr_stats.loc[grp, (arm, feature)] = list(scipy.stats.ttest_1samp(\n",
    "                np.arctanh(neural_corr.loc[idx[:, :, grp], (arm, feature, 'r')]),\n",
    "                0,\n",
    "                nan_policy='omit'\n",
    "            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T20:59:11.325926Z",
     "start_time": "2018-02-13T20:59:10.403454Z"
    }
   },
   "source": [
    "### Figure 4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T20:59:11.325926Z",
     "start_time": "2018-02-13T20:59:10.403454Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2)\n",
    "\n",
    "cdf(neural_arm['closed'].values, ax=axes[0], label='closed')\n",
    "cdf(neural_arm['open'].values, ax=axes[0], label='open')\n",
    "axes[0].legend()\n",
    "axes[0].set_xlabel('mean_response')\n",
    "\n",
    "data = neural_arm[['closed', 'open']]\n",
    "ax0 = sns.stripplot(ax=axes[1], data=data.melt(), x='arm', y='value', s=3, jitter=True, zorder=0)\n",
    "ax1 = sns.pointplot(ax=axes[1], data=data.melt(), x='arm', y='value', scale=0.5, color='k', ci=68, join=False)\n",
    "# axes[1].errorbar(range(2), data.mean(), data.sem(), c='k', fmt='_', zorder=100)\n",
    "\n",
    "test_val, p_val = scipy.stats.wilcoxon(neural_arm['open'], neural_arm['closed'])\n",
    "fig.suptitle('Wilcoxon signed-rank test\\nW: {}\\np: {}'.format(test_val, p_val))\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.85])\n",
    "\n",
    "if save_plot:\n",
    "    plt_name = os.path.join(output_dir, 'fig4d')\n",
    "    fig.savefig(plt_name + '.pdf')\n",
    "    fig.savefig(plt_name + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T20:59:10.402205Z",
     "start_time": "2018-02-13T20:59:09.822980Z"
    }
   },
   "source": [
    "### Figure 4E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T20:59:10.402205Z",
     "start_time": "2018-02-13T20:59:09.822980Z"
    }
   },
   "outputs": [],
   "source": [
    "counts = neural_arm.groupby('response').count()['center']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "counts.plot.pie(ax=ax, autopct='%1.1f%%', wedgeprops={'lw': 5, 'ec': 'w'})\n",
    "ax.axis('image')\n",
    "centre_circle = plt.Circle((0, 0), 1 / 1.4142, color='none', fc='white')\n",
    "ax.add_artist(centre_circle);\n",
    "\n",
    "if save_plot:\n",
    "    plt_name = os.path.join(output_dir, 'fig4e')\n",
    "    fig.savefig(plt_name + '.pdf')\n",
    "    fig.savefig(plt_name + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T20:59:08.755743Z",
     "start_time": "2018-02-13T20:59:04.897620Z"
    }
   },
   "source": [
    "### Figure 4H,I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T20:59:08.755743Z",
     "start_time": "2018-02-13T20:59:04.897620Z"
    }
   },
   "outputs": [],
   "source": [
    "data = neural_zone.copy()\n",
    "data = data.drop(itertools.product(bin_labels[1:], ['center']))\n",
    "data = data.drop(itertools.product([0.0], ['closed', 'open']))\n",
    "data = data.drop('na', level='zone')\n",
    "\n",
    "n_rows = data.shape[0]\n",
    "data = data.iloc[list(range(n_rows-2, 0, -2)) + list(range(0, n_rows, 2))]\n",
    "\n",
    "sort_ix_peak = np.nanargmax(data.values, axis=0).argsort()\n",
    "sort_ix = data.mean(axis=0, level='zone')\n",
    "sort_ix = sort_ix.loc['open'] / sort_ix.loc['closed']\n",
    "sort_ix_mean = sort_ix.values.argsort()\n",
    "\n",
    "gridspec_kw = {'height_ratios': [3, 1], 'width_ratios': [2, 0.1]}\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(6, 8), sharex='col', gridspec_kw=gridspec_kw)\n",
    "sns.heatmap(data.iloc[:, sort_ix_mean].T, ax=axes[0, 0], center=0, vmax=2, cbar_ax=axes[0, 1]);\n",
    "\n",
    "data_long = data.copy()\n",
    "data_long.columns = pd.MultiIndex.from_tuples(\n",
    "    [x + (y, ) for x, y in zip(data.columns, neural_response.loc['group', data.columns].astype(int))],\n",
    "    names=data.columns.names + ['group']\n",
    ")\n",
    "data_long = data_long.stack(list(range(data_long.columns.nlevels))).reset_index().rename(columns={0: 'neural'})\n",
    "data_long['arm_loc'] = data_long['zone'] + ' ' + data_long['distance_from_center'].astype(str)\n",
    "zone_order = (\n",
    "    [' '.join(x) for x in itertools.product(['closed'], bin_labels[-1:0:-1].astype(str))] +\n",
    "    ['center 0.0'] +\n",
    "    [' '.join(x) for x in itertools.product(['open'], bin_labels[1:].astype(str))]\n",
    ")\n",
    "sns.lineplot(data=data_long, x='arm_loc', y='neural', hue='group',\n",
    "             hue_order=[-1, 0, 1], ci=68, ax=axes[1, 0], sort=False)\n",
    "for ax in axes[1]:\n",
    "    plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "sns.despine(ax=axes[1, 0])\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "if save_plot:\n",
    "    plt_name = os.path.join(output_dir, 'fig4hi')\n",
    "    fig.savefig(plt_name + '.pdf')\n",
    "    fig.savefig(plt_name + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 4J,K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_corr_long = neural_corr['open'].xs('r', axis=1, level='stat').stack(list(range(neural_corr.columns.nlevels - 2))).reset_index().rename(columns={0: 'r'})\n",
    "features = ['distance_from_center', 'velocity']\n",
    "g = sns.FacetGrid(\n",
    "    neural_corr_long, row='feature', hue='group',\n",
    "    row_order=features, hue_order=[-1, 0, 1], aspect=1.25\n",
    ")\n",
    "g.map(cdf, 'r').add_legend()\n",
    "\n",
    "# Format\n",
    "for ax, feature in zip(g.axes.flatten(), features):\n",
    "    grp_stats = neural_corr_stats[('open', feature)]\n",
    "    ax.set_xlim(-0.75, 0.75)\n",
    "    ax.set_title(\n",
    "        f'{ax.get_title()}\\n'\n",
    "        f\"inh | W: {grp_stats.loc[-1, 't']:.2e} p: {grp_stats.loc[-1, 'p']:.2e}\\n\"\n",
    "        f\"nc | W: {grp_stats.loc[0, 't']:.2e} p: {grp_stats.loc[0, 'p']:.2e}\\n\"\n",
    "        f\"exc | W: {grp_stats.loc[1, 't']:.2e} p: {grp_stats.loc[1, 'p']:.2e}\\n\"\n",
    "    )\n",
    "g.fig.tight_layout(rect=[0, 0, 0.95, 1])\n",
    "\n",
    "if save_plot:\n",
    "    plt_name = os.path.join(output_dir, 'fig4jk')\n",
    "    g.fig.savefig(plt_name + '.pdf')\n",
    "    g.fig.savefig(plt_name + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
